services:
  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    user: "1000:1000"
    ports:
      - "5678:5678"
    environment:
      - N8N_HOST=0.0.0.0
      - N8N_PORT=5678
      - N8N_EDITOR_BASE_URL=http://localhost:5678
      - GENERIC_TIMEZONE=America/Bogota
    volumes:
      - ./n8n_data:/home/node/.n8n
      - ./resultados:/data/resultados
    depends_on:
      - transcriber
      - ollama

  transcriber:
    build: ./transcriber
    container_name: transcriber
    ports:
      - "5000:5000"
    environment:
      - MODEL=base
    volumes:
      - ./uploads:/app/uploads

  ollama:
    image: ollama/ollama:latest
    container_name: ollama-3
    # Recommended for GPU support (uncomment if you have NVIDIA GPU)
    # runtime: nvidia
    # environment:
    #   - NVIDIA_VISIBLE_DEVICES=all
    #   - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_KEEP_ALIVE=3600
    command: ["serve"]


volumes:
  ollama_data:


