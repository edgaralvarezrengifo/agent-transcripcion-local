# Agente de Transcripci√≥n de Archivos Multimedia
Caso de Uso ‚Äî Proyecto de Grado: Implementaci√≥n de agentes de IA con LLMs locales en entornos seguros

## üß© Descripci√≥n General

Este repositorio implementa un agente local de transcripci√≥n autom√°tica de archivos multimedia (audio o video), dise√±ado para operar en entornos institucionales sin conexi√≥n a la nube.

El agente integra tres componentes principales:

n8n ‚Üí motor de orquestaci√≥n de flujos.

Transcriber Service (Whisper) ‚Üí microservicio local basado en Ollama + Whisper.

Ollama ‚Üí entorno de ejecuci√≥n de modelos de lenguaje y ASR (Automatic Speech Recognition).

El objetivo es demostrar la viabilidad de ejecutar agentes de IA con LLMs locales en escenarios reales de procesamiento acad√©mico, como la transcripci√≥n de clases, conferencias o entrevistas.

## üèóÔ∏è Componentes Principales
| Componente              | Funci√≥n                                                                 | Tecnolog√≠a                  |
| ----------------------- | ----------------------------------------------------------------------- | --------------------------- |
| **Ollama**              | Ejecuta modelos LLM y ASR localmente.                                   | [Ollama](https://ollama.ai) |
| **Transcriber Service** | API REST que gestiona la transcripci√≥n de audio/video mediante Whisper. | Python + Flask              |
| **n8n**                 | Orquestador del flujo general: carga ‚Üí transcripci√≥n ‚Üí almacenamiento.  | [n8n.io](https://n8n.io)    |


## üß† Flujo de Trabajo (Workflow en n8n)

Accede a:

http://localhost:5678

Flujo base sugerido:

| Paso | Nodo                      | Descripci√≥n                                                        |
| ---- | ------------------------- | ------------------------------------------------------------------ |
| 1    | **Read Binary File**      | Carga el archivo multimedia desde `/data/input`.                   |
| 2    | **HTTP Request**          | Envia el archivo al endpoint `http://transcriber:8000/transcribe`. |
| 3    | **Set / Function Node**   | Extrae el texto del campo `response`.                              |
| 4    | **Write File / Database** | Guarda la transcripci√≥n en `/data/output/`.                        |


üß∞ Requisitos Previos

- Docker y Docker Compose instalados.

- Al menos 8 GB de RAM (recomendado 16 GB para procesar videos largos).

- Modelos descargados localmente:
```bash
ollama pull whisper
```

## üöÄ Ejecuci√≥n

1. Clonar el repositorio:
```bash
git clone https://github.com/<usuario>/agent-transcripcion-local.git
cd agent-transcripcion-local
```

2. Iniciar los servicios:
```bash
docker compose up -d
```

3. Acceder a n8n:
```bash
http://localhost:5678
```

4. Crear el flujo (workflow):

  - Agregar nodo File Upload / HTTP Request (para recibir el archivo).

  - Agregar nodo HTTP Request para llamar a Ollama Whisper.

  - Agregar nodo Write Binary File / Database / Email para guardar o enviar la transcripci√≥n.

## üß™ Ejemplo de prueba directa del microservicio
```bash
curl -X POST http://localhost:8000/transcribe \
  -F "file=@data/input/clase1.mp3"
```

Salida esperada:

{
  "response": "Bienvenidos a la clase de hoy sobre inteligencia artificial aplicada a la educaci√≥n..."
}

## üß± Directorios del Proyecto
```bash
agent-transcripcion-local/
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ transcriber/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ input/
‚îÇ   ‚îî‚îÄ‚îÄ output/
‚îú‚îÄ‚îÄ n8n_data/
‚îú‚îÄ‚îÄ ollama_data/
‚îî‚îÄ‚îÄ README.md
```
## üîê Consideraciones de Privacidad y Seguridad

- Todos los procesos se ejecutan localmente, sin enviar datos a servidores externos.

- Los archivos de audio/video no abandonan el entorno institucional.

- Las variables de entorno se manejan mediante Docker Compose.

## üìö Referencias T√©cnicas

n8n Documentation

Ollama Whisper

OpenAI Whisper GitHub

Docker Compose


## ‚öôÔ∏è Arquitectura del Agente

```mermaid
flowchart LR
    A["Archivo multimedia: MP4 / MP3 / WAV"] --> B["n8n - Flujo de orquestaci√≥n"]
    B --> C["Transcriber Service (Flask API)"]
    C --> D["Ollama - Modelo Whisper"]
    D --> E["Texto transcrito"]
    E --> F["Almacenamiento local o base de datos"]
